In this file, we aim to get data ready for modeling by:

-   Identifying treatment episode duration and early adherence indicator
    using the AdhereR package.

-   Define outcomes of interest:

    -   1.  Binary outcome: treatment continuation vs.Â discontinuation
            using a threshold.  
    -   1.  Treatment duration categories: long, medium-extended, medium
            and short duration.

## 1. Data Preprocessing

    knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
    setwd("A:/iqvia_bauer_extract_refresh/ANALYTICAL FILES")

    library(data.table)
    library(ggplot2) 
    library(plotly)
    library(gridExtra)
    library(tidyr)
    library(tidyverse)
    library(AdhereR)
    library(table1)

    ## read in filtered claims data with our criteria defined in 01_Data_processing that have been merged with demographic and enrollment info

    ## all data records
    claims_demo <- fread("../Processed_data/claims_demo_enroll_filtered.csv")

### Clean days of supply (dayssup)

Looking at the distribution of days in the final dataset, some extreme
values exist such as negative and 999. We clean the dayssup by:

-   replace the missing, negative and 0 values of dayssup variable with
    its median;

-   and put 90 days as the maximum value for dayssup by replacing
    anything greater to 90 with its median.

We also calculate the proportion of entries with dayssup greater than
90: less than 0.002 %.

    table(claims_demo$dayssup) 

    hist(claims_demo$dayssup)

    # replace missing values with median
    claims_demo$dayssup[is.na(claims_demo$dayssup)] <- median(claims_demo$dayssup[claims_demo$dayssup > 0], na.rm = TRUE)

    # Replace negative and zero values of dayssup with its median
    claims_demo$dayssup[claims_demo$dayssup <= 0] <- median(claims_demo$dayssup[claims_demo$dayssup > 0], na.rm = TRUE)


    # Calculate the proportion of entries with dayssup greater than 90
    prop_greater_90 <- mean(claims_demo$dayssup > 90, na.rm = TRUE)
    # 1.967878e-05

    # Put 90 days as the maximum value for dayssup, change anything greater to 90
    claims_demo$dayssup[claims_demo$dayssup > 90] <- 90

    print(paste("Percentage of entries with dayssup greater than 90:", prop_greater_90*100))

## 2. Identifying the treatment episodes with 14 days allowable gaps

    ## Prepare buprenorphine events
    filter_bupre_unique <- claims_demo %>%
      filter(!is.na(dayssup) & dayssup > 0) %>%
      distinct() ## 4,483,809 records

    ## Episode construction with 14-day maximum permissible gap
    Bup_episode <- compute.treatment.episodes(
      filter_bupre_unique,
      ID.colname = "pat_id",
      event.date.colname = "from_dt",
      event.duration.colname = "dayssup",
      carryover.within.obs.window = TRUE,
      medication.change.means.new.treatment.episode = FALSE,
      maximum.permissible.gap = 14,
      maximum.permissible.gap.unit = "days",
      followup.window.start = 0,
      followup.window.start.unit = "days",
      followup.window.duration = 365 * 24,  # large window to ensure carryover is included
      followup.window.duration.unit = "days",
      date.format = "%m/%d/%Y",
      return.mapping.events.episodes = TRUE
    )

    event_mapping <- getEventsToEpisodesMapping(Bup_episode)

    # View and save results
    head(Bup_episode)
    fwrite(Bup_episode, "../Processed_data/Bup_episode.csv")

### Extra-step - Sensitivity analysis

    compute_summaries_and_histograms <- function(filtered_bupre_unique, demo, gaps) {
      # Initialize a list to store summaries
      combined_summaries <- list()
      
      # Loop through each gap value
      for (i in seq_along(gaps)) {
        # Compute treatment episodes for each gap value
        Bup_episode <- compute.treatment.episodes(
          #final_data_filtered,
          filter_bupre_unique,
          ID.colname = "pat_id",
          event.date.colname = "from_dt",
          event.duration.colname = "dayssup",
          carryover.within.obs.window = TRUE,
          medication.change.means.new.treatment.episode = FALSE,
          maximum.permissible.gap = gaps[i],
          maximum.permissible.gap.unit = "days",
          followup.window.start = 0,
          followup.window.start.unit = "days",
          followup.window.duration = 365 * 24, # Allow long enough duration to include the medication carryover time
          followup.window.duration.unit = "days",
          date.format = "%m/%d/%Y"
        )
        
        # Convert episode.start to Date format
        Bup_episode <- Bup_episode %>%
          mutate(episode.start = as.Date(episode.start, format = "%m/%d/%Y"))
        
        # Merge Bup_episode and demo data frames by pat_id
        merged_data <- Bup_episode %>%
          left_join(demo, by = "pat_id")
        
        # Select the last episode for each patient
        last_episode_data <- merged_data %>%
          group_by(pat_id) %>%
          slice_tail(n = 1) %>%
          ungroup()
        
        # Summarize the last episodes data
        summary_bup_episode <- last_episode_data %>%
          summarize(
            mean_episodes = mean(episode.ID, na.rm = TRUE),
            median_episodes = median(episode.ID, na.rm = TRUE),
            sd_episodes = sd(episode.ID, na.rm = TRUE),
            min_episodes = min(episode.ID, na.rm = TRUE),
            max_episodes = max(episode.ID, na.rm = TRUE))
        
        # Create histogram for episode.ID
        histogram_episode_id <- ggplot(last_episode_data, aes(x = episode.ID)) +
          geom_histogram(binwidth = 1, fill = "blue", color = "black", alpha = 0.7) +
          labs(title = paste("Histogram of Number of Episodes (Gap:", gaps[i], "days)"),
               x = "Episode.ID",
               y = "Count") +
          theme_minimal() 
        
        # Summarize the mean episode duration data
        summary_median_duration <- merged_data %>%
          summarize(
            mean_d = mean(episode.duration, na.rm = TRUE),
            sd_d = sd(episode.duration, na.rm = TRUE),
            min_d = min(episode.duration, na.rm = TRUE),
            max_d = max(episode.duration, na.rm = TRUE),
            median_d = median(episode.duration, na.rm = TRUE),
            q25_d = quantile(episode.duration, 0.25, na.rm = TRUE),
            q75_d = quantile(episode.duration, 0.75, na.rm = TRUE)) 
        
        # Create histogram for mean episode duration
        histogram_median_duration <- ggplot(merged_data, aes(x = episode.duration)) +
          geom_histogram(binwidth = 5, fill = "blue", color = "black", alpha = 0.7) +
          labs(title = paste("Histogram of Median Episode Duration (Gap:", gaps[i], "days)"),
               x = "Median Episode Duration",
               y = "Count") +
          theme_minimal()
        
        # Display the histograms side by side
        grid.arrange(histogram_episode_id, histogram_median_duration, ncol = 2)
        
        # Combine summaries into one table for this gap
        combined_summary <- summary_bup_episode %>%
          bind_cols(summary_median_duration)  
        
        # Store the combined summary in the list
        combined_summaries[[paste("Gap", gaps[i], "days")]] <- combined_summary
      }
      
      # Return the list of combined summaries
      return(combined_summaries)
    }

    gap_values <- c(7, 14, 28, 30, 60, 90)
    combined_summaries <- compute_summaries_and_histograms(filtered_bupre_unique, demo, gap_values)

    combined_summaries 

## 3. Merged Demographic, Enrollment, Diagnostic, and Procedures data;

In this step, we create diagnostic, procedures and early treatment
adherence variables.

### Step 1 - Create the PDC90 variable

    ## Compute PDC (CMA7) over a 90-day window
    ## continuous multiple-interval measures of medication availability/gaps
    Bup_episode <- fread("../Processed_data/Bup_episode.csv")
    Bup_episode$ID <- 1:nrow(Bup_episode)
    pdc_results <- CMA7(
      data = Bup_episode, #episode_data1,
      ID.colname = "ID",
      event.date.colname = "episode.start",
      event.duration.colname = "episode.duration",
      followup.window.start = 0,
      followup.window.duration = 30,       # 90-day window
      observation.window.start = 0,
      observation.window.duration = 30
    )

    # Preview result
    head(pdc_results)

    ## Extract just the CMA values per patient
    pdc_df <- pdc_results$CMA

    ## Save as CSV
    fwrite(pdc_df, "../Processed_data/pdc_results_30.csv")

### Step 2 - Join demographic data and remove NAs.

    # --- Load datasets ---
    demographic <- read.csv("../bauer_extract_enroll.csv")

    ###create episode_demo
    # Merge Bup_episode with demographic data using pat_id
    episode_demo <- Bup_episode %>%
      left_join(demographic, by = "pat_id")

    # Optional: save the result
    fwrite(episode_demo, "../Processed_data/Bup_episode_demo.csv")

    # View head of the result
    head(episode_demo)

#### Identify index date and extract diagnosis records 12 months before index date for each patient

    # Step 1: Identify index date (first prescription date) per patient
    index_lookup <- claims_demo[, .(index_date = min(from_dt, na.rm = TRUE)), by = pat_id]
    setkey(index_lookup, pat_id)

    # Step 2: Setup for chunked processing
    raw_file <- "../bauer_extract_claims.csv"
    output_file <- "filtered_pre_index_diag_all.csv"
    chunk_size <- 5e6
    i <- 0

    # Step 3: Count total lines 
    n_total <- 90327620 

    # Step 4: Process raw claims data in chunks

    for (i in seq(0, n_total, by = chunk_size)) {

      nrows_to_read <- min(chunk_size, n_total - i)

      cat("Processing rows", i + 1, "to", i + nrows_to_read, "\n")

      # Read chunk with only needed columns
      chunk <- fread(
        raw_file,
        skip = i + (i > 0),
        nrows = nrows_to_read,
        header = (i == 0)
      )
      
       names(chunk) <- c("pat_id", "claimno", "rectype", "proc_cde", "ndc", "dayssup", "quan", "srv_unit", "from_dt", "to_dt", "diagprc_ind",
                        "diag1", "diag2", "diag3", "diag4", "diag5", "diag6", "diag7", "diag8", "diag9", "diag10", "diag11", "diag12", "bill_id",
                        "prscbr_id", "month_id")
      chunk <- select(chunk, c("pat_id", "from_dt", paste0("diag", 1:12)), "diagprc_ind")

      # Convert date column
      chunk[, from_dt := as.IDate(from_dt)]
      # Filter to patients in index_lookup
      chunk <- chunk[pat_id %in% index_lookup$pat_id]
      # Add index_date to chunk
      chunk <- merge(chunk, index_lookup, by = "pat_id", all.x = TRUE)
      # Filter: from_dt within 12 months prior to index_date
      chunk <- chunk[from_dt < index_date & from_dt >= (index_date - 365)]

      # Write to output CSV (append after first chunk)
      fwrite(chunk, output_file, append = (i > 0))

      rm(chunk)
      gc()

    }

### Step 3 - Create diagnostic and procedures codes using ICD and CPT codes, add the early treatment adhrence predictors - pdc90 and dayssup.

#### ICD 9 and ICD 10 codes for diagnosis extraction

We compared two different methods in ICD-9 code matching:

-   convert ICD-9 code in our dataset to ICD-10 code using R package icd

-   matching ICD-9 code with the listed code for each diagnosis
    (similarly for ICD-10), where we used the ICD10 to ICD9 code
    crosswalk file from the CMS.

**Method 1**

    #################################################
    # First method: ICD-9 codes conversion
    ###############################################

    ## Read in ICD-9 and ICD-10 codes from the extracted table 
    diagnosis <- fread("../Processed_data/filtered_pre_index_diag_updated.csv")
    dx_codes <- read.csv("../bauer_extract_dx_lookup.csv") %>%
      distinct(dx_cd, .keep_all=T) # diagnosis code-to-desc mapping 

    # convert to long format for matching 
    diag_long <- diagnosis %>%
      select(-diagprc_ind) %>%
      select(pat_id, starts_with("diag")) %>%
      pivot_longer(cols = starts_with("diag"), names_to = "var", values_to = "code") %>%
      filter(!is.na(code), code != "") %>%
      mutate(code = toupper(code)) %>%
      left_join(dx_codes, by=c("code"="dx_cd"))

    # sum(diagnosis[, paste0("diag", 1:12)] != "" & !is.na(diagnosis[, paste0("diag", 1:12)]))
    # depression_codes <- c("F32", "F32.0", "F32.1", "F32.2", "F32.3", "F32.8", "F32.9",
    #                       "F33", "F33.0", "F33.1", "F33.2", "F33.3", "F33.8", "F33.9",
    #                       "F34.1")

    ## extract unique entries of ICD-9 code
    diag_icd9 <- diagnosis %>%
      filter(diagprc_ind==1) %>%
      select(-diagprc_ind) %>%
      select(pat_id, starts_with("diag")) %>%
      pivot_longer(cols = starts_with("diag"), names_to = "var", values_to = "code") %>%
      filter(!is.na(code), code != "") %>%
      mutate(code = toupper(code)) %>%
      left_join(dx_codes, by=c("code"="dx_cd"))

    icd9_code <- unique(diag_icd9$code)

    ## save and export for conversion
    saveRDS(icd9_code,"icd9_code.rds")

    #remotes::install_github("jackwasey/icd")
    #pak::pkg_install("jackwasey/icd") ## not working 
    #library(icd)

    ## read in converted code 
    icd9_to_icd10 <- readRDS("../Processed_data/icd9_to_icd10.rds")
    ## now create new icd code variable
    diag_long <- left_join(diag_long, icd9_to_icd10, by = c("code"="ICD_input")) %>%
      mutate(ICD_code = ifelse(!is.na(ICD10), ICD10, code))

    # --- Step 1: Define comorbidity flags using ICD-10 ---
    # icd_flags1 <- diag_long %>%
    #   group_by(pat_id) %>%
    #   summarise(
    #     #depression = any(diagnosis %in% depression_codes))
    #     depression = any(str_detect(diagnosis, "^(F32|F33|F34\\.1)")),
    #     anxiety    = any(str_detect(diagnosis, "^(F40|F41|F42)")),
    #     ptsd       = any(str_detect(diagnosis, "^F43\\.1")),
    #     bipolar    = any(str_detect(diagnosis, "^(F31|F34\\.0)")),
    #     schizo     = any(str_detect(diagnosis, "^(F20|F21|F25)")),
    #     hiv        = any(str_detect(diagnosis, "^B2[0-4]")),
    #     hepc       = any(str_detect(diagnosis, "^(B17\\.1[01]|B18\\.2|B19\\.2[01])")),
    #     alcohol    = any(str_detect(diagnosis, "^F10")),
    #     nodrug     = any(str_detect(diagnosis, "^F1[2-9]")),
    #     .groups = "drop"
    #   ) %>%
    #   ungroup()

    icd_flags <- diag_long %>%
      group_by(pat_id) %>%
      summarise(
        depression = any(str_detect(ICD_code, "^(F32|F33|F341)")),
        anxiety    = any(str_detect(ICD_code, "^(F40|F41|F42)")),
        ptsd       = any(str_detect(ICD_code, "^F431")),
        bipolar    = any(str_detect(ICD_code, "^(F31|F340)")),
        schizo     = any(str_detect(ICD_code, "^(F20|F21|F25)")),
        hiv        = any(str_detect(ICD_code, "^B2[0-4]")),
        hepc       = any(str_detect(ICD_code, "^(B1710|B1711|B182|B1920|B1921)")),
        alcohol    = any(str_detect(ICD_code, "^F10")),
        nodrug     = any(str_detect(ICD_code, "^F1[2-9]")),
        .groups = "drop"
      ) %>%
      ungroup()


    fwrite(icd_flags, "../Processed_data/ICD_flags_v1.csv")

**Method 2**:

    #################################################
    # Alternative method for ICD-9 codes extraction
    ###############################################
    icd_map <- readxl::read_excel("../Processed_data/ICD9-ICD10Codes_BupProj.xlsx")
    names(icd_map) <- c("category", "ICD9", "ICD10")

    # helper -------------------------------------------------------------
    collapse_icd_codes <- function(code_string){
      if (length(code_string) == 0 || all(is.na(code_string)))
        return(character(0))

      code_string |>
        str_split(",") |>            # split comma-separated list
        unlist() |>
        str_replace_all("\\.", "") |> # remove dots
        str_trim() |>
        discard(~ .x == "")           # drop empties
    }

    # one regex *per row* -----------------------------------------------
    icd_patterns <- icd_map %>%                             # â your lookup table
      mutate(
        combined_pattern = map2_chr(                        # <- iterates row-wise
          ICD9, ICD10,
          ~{
            codes <- unique(c(collapse_icd_codes(.x),
                              collapse_icd_codes(.y)))
            if (length(codes) == 0) NA_character_           # keep NA if no codes
            else paste0("^(", paste(codes, collapse = "|"), ")")
          }
        )
      )


    icd_flags1 <- diag_long %>%
      mutate(diagnosis = str_replace_all(diagnosis, "\\.", "")) %>%  # normalize codes
      group_by(pat_id) %>%
      summarise(
        depression = any(str_detect(diagnosis, icd_patterns[icd_patterns$category== "Depressive disorder",]$combined_pattern)),
        anxiety    = any(str_detect(diagnosis, icd_patterns[icd_patterns$category=="Anxiety",]$combined_pattern)),
        ptsd       = any(str_detect(diagnosis, icd_patterns[icd_patterns$category=="Post-traumatic stress disorder (PTSD)",]$combined_pattern)),
        bipolar    = any(str_detect(diagnosis, icd_patterns[icd_patterns$category=="Bipolar disorder",]$combined_pattern)),
        schizo     = any(str_detect(diagnosis, icd_patterns[icd_patterns$category=="Schizophrenia",]$combined_pattern)),
        
        hiv        = any(str_detect(diagnosis, icd_patterns[icd_patterns$category=="HIV",]$combined_pattern)),
        hepc       = any(str_detect(diagnosis, icd_patterns[icd_patterns$category=="Hep C",]$combined_pattern)),
        
        alcohol    = any(str_detect(diagnosis, icd_patterns[icd_patterns$category=="Alcohol use disorder",]$combined_pattern)),
        nodrug     = any(str_detect(diagnosis, icd_patterns[icd_patterns$category=="Non-opioid drug use disorder",]$combined_pattern)),

        .groups = "drop"
      ) %>%
      ungroup()

    icd_flags1[is.na(icd_flags1)] <- FALSE


    fwrite(icd_flags1, "../Processed_data/ICD_flags_v2.csv")

**Quick Comparison**:

    ### quick comparison
    library(table1)

    # v1: original Paula's list (added two to depression)
    # v2: icd package

    icd_flags <- fread("../Processed_data/ICD_flags_v1.csv")

    icd_flags$version <- "Conversion"
    icd_flags1$version <- "Extraction"

    icd_flags_combined <- bind_rows(icd_flags, icd_flags1)

    table1(~depression + anxiety + ptsd + bipolar + schizo + hiv + hepc + alcohol + nodrug |version, data = icd_flags_combined)

    #table1(~depression + anxiety + ptsd + bipolar + schizo + hiv + hepc + alcohol + nodrug, data = icd_flags1)

The two methods gave us very similar results - we proceeded with the
second method so that we can explicitly list the ICD-9 codes used to
extract diagnosis.

#### CPT codes for procedure records extraction

    ### extract records for CPT flags 
    # Step 1: Identify index date (first prescription date) per patient
    index_lookup <- claims_demo[, .(index_date = min(from_dt, na.rm = TRUE)), by = pat_id]
    setkey(index_lookup, pat_id)

    # Step 2: Setup for chunked processing
    raw_file <- "../bauer_extract_claims.csv"
    output_file <- "filtered_pre_post_index_proc.csv"
    chunk_size <- 5e6
    i <- 0

    # Step 3: Count total lines 
    n_total <- 90327620 

    # Step 4: Process raw claims data in chunks
    for (i in seq(0, n_total, by = chunk_size)) {

      nrows_to_read <- min(chunk_size, n_total - i)
      cat("Processing rows", i + 1, "to", i + nrows_to_read, "\n")

      # Read chunk with only needed columns
      chunk <- fread(
        raw_file,
        skip = i + (i > 0),
        nrows = nrows_to_read,
        header = (i == 0)
      )
      
       names(chunk) <- c("pat_id", "claimno", "rectype", "proc_cde", "ndc", "dayssup", "quan", "srv_unit", "from_dt", "to_dt", "diagprc_ind",
                        "diag1", "diag2", "diag3", "diag4", "diag5", "diag6", "diag7", "diag8", "diag9", "diag10", "diag11", "diag12", "bill_id",
                        "prscbr_id", "month_id")
       
      chunk <- select(chunk, c("pat_id", "from_dt", "proc_cde"))

      # Convert date column
      chunk[, from_dt := as.IDate(from_dt)]
      # Filter to patients in index_lookup
      chunk <- chunk[pat_id %in% index_lookup$pat_id]
      # Add index_date to chunk
      chunk <- merge(chunk, index_lookup, by = "pat_id", all.x = TRUE)
      # Filter: from_dt within 12 months prior to index_date
      chunk <- chunk[from_dt <= (index_date + 365) & from_dt >= (index_date - 365)]
      
      # Write to output CSV (append after first chunk)
      fwrite(chunk, output_file, append = (i > 0))
      
      rm(chunk)
      gc()

    }

    procedure <- fread("filtered_pre_post_index_proc.csv")

    # --- Define CPT flags ---
    cpt_flags <- procedure %>%
      group_by(pat_id) %>%
      summarise(
        outpatient = any(str_detect(proc_cde, "^9920[1-5]$|^9921[1-5]$|^9924[1-5]$")),
        psychiatric = any(str_detect(proc_cde, "^9080[1-2]$|^9080[4-9]$|^9081[0-5]$|^9084[5-7]$|^908[6-9][2-9]$")),
        mat = any(str_detect(proc_cde, "^G2080$")),
        telehealth = any(str_detect(proc_cde, "^9944[1-3]$")),
        induction = any(str_detect(proc_cde, "^9935[4-5]$")),
        bupre_tx = any(str_detect(proc_cde, "^T1015$")),
        .groups = "drop"
      )

    fwrite(cpt_flags, "../Processed_data/CPT_flags.csv")

### Step 4: Merge all into a master dataset for modeling

    episode_demo <- fread("../Processed_data/Bup_episode_demo.csv")
    enrollment <- read.csv("../bauer_extract_enroll2.csv")
    pdc_df_90 <- fread("../Processed_data/pdc_results_90.csv")
    pdc_df_30 <- fread("../Processed_data/pdc_results_30.csv")
    icd_flags <- fread("../Processed_data/ICD_flags_v2.csv") ## use list 
    cpt_flags <- fread("../Processed_data/CPT_flags.csv")

    merged_data <- episode_demo %>%
      mutate(month_id=as.numeric(paste0(substr(episode.start,1,4), substr(episode.start,6,7)))) %>%
      left_join(enrollment, by = c("pat_id", "month_id")) %>%
      left_join(pdc_df_90 %>% rename(pdc_90 = CMA), by = "ID") %>%
      left_join(pdc_df_30 %>% rename(pdc_30 = CMA), by = "ID") %>%
      left_join(icd_flags, by = "pat_id") %>%
      left_join(cpt_flags, by = "pat_id") #%>%
     # filter(age >= 18)

    ## clean demographic variables 
    merged_data <- merged_data %>%
      mutate(start.year=year(episode.start),
             age=start.year-der_yob,
             sex = ifelse(der_sex == "F", "Female", ifelse(der_sex == "M", "Male", NA)),
             zip3 = ifelse(pat_zip3 %in% c("", " ", "."), NA,
                           ifelse(pat_zip3 %in% c("87", "88"), stringi::stri_pad_left(pat_zip3, 3, "0"),
                                  ifelse(nchar(pat_zip3)==3, pat_zip3, NA))),
             pat_region = case_when(
               pat_region=="E" ~ "East",
               pat_region=="S" ~ "South",
               pat_region=="MW" ~ "Midwest",
               pat_region=="W" ~ "West",
               TRUE ~ NA
             ),
             pay_type = case_when(
              pay_type == "C" ~ "Commercial",
              pay_type == "K" ~ "State Children's Health Insurance Program",
              pay_type == "M" ~ "Medicaid",
              pay_type == "R" ~ "Medicare Risk", 
              pay_type == "S" ~ "Self-insured", 
              pay_type == "T" ~ "Medicare Cost", 
              pay_type == "U" ~ NA,
              TRUE ~ NA
             )
      )

    # Final selection
    final_data <- merged_data %>%
      select(pat_id, sex, pat_region, age, pay_type, everything()) #%>%
      #filter_all(all_vars(!is.na(.) & . != ""))

    # Export result ---
    fwrite(final_data, "../Processed_data/merged_demo_enroll_diag_proc_v2.csv")

    # View a sample
    head(final_data, 10) 

## 4. Define outcome - discontinued - as episode duration &lt; 180 days.

    # final_data <- fread("../Processed_data/merged_demo_enroll_diag_proc_v2.csv")
    # Define 'discontinued' based on episode duration
    episode_model <- final_data %>%
      mutate(discontinued = ifelse(episode.duration < 180, 1, 0))

## 5. Merge with the Contectual SDOH data file created by Paula on 3-digit ZIP codes

    episode_model$pat_zip3 <- as.character(episode_model$pat_zip3) 
    variables_project_BTD <- fread("../Processed_data/buprenorphine_duration_project_variables.csv")
    colnames(variables_project_BTD)[1]<-"zip3"
    variables_project_BTD$zip3 <- stringi::stri_pad_left(variables_project_BTD$zip3,3, "0")


    episode_model_sdoh <- episode_model %>% 
      left_join(variables_project_BTD, by = "zip3") %>%
      #filter(!is.na(sex) & !is.na(age) & !is.na(pay_type)) %>%
      #filter(age >=18 & age <=85) %>%
      mutate(age_group = case_when(
        age >=18 & age <= 34 ~ "18-34",
        age >=35 & age <= 54 ~ "35-54",
        age >=55 & age <=85 ~ "55-85"
      ))

    fwrite(episode_model_sdoh, "../Processed_data/Modeling/episode_model_df_v2.csv")

**episode\_model\_df\_v2.csv is used for multinomial logistic regression
model**.

### Identify patient IDs with 12-month enrollment limit

In this step, we identify patients (pat\_id) with at least 12-month of
enrollment in the longitudinal database.

    my_data <- fread("../Processed_data/claims_demo_filtered.csv")
    # ------------------------------------------------------------------
    # 0.  Inputs --------------------------------------------------------
    # ------------------------------------------------------------------
    big_file   <- "../bauer_extract_claims.csv"          # huge CSV with pat_id, from_dt, to_dt â¦
    id_keep    <- unique(my_data$pat_id)    # vector of patients you care about
    chunk_size <- 5e6                       # rows per chunk

    # Make a fast lookup table for the IDs
    id_tbl <- data.table(pat_id = id_keep);  setkey(id_tbl, pat_id)

    # ------------------------------------------------------------------
    # 1.  initialise an empty accumulator ------------------------------
    # ------------------------------------------------------------------
    ranges <- data.table(
      pat_id   = character(),
      min_from = as.IDate(character()),
      max_to   = as.IDate(character())
    )
    setkey(ranges, pat_id)

    # accurate line count (header excluded)
    n_total <- 90327620 
    rows_so_far <- 0L    
    # ------------------------------------------------------------------
    # 2.  streaming loop -----------------------------------------------
    # ------------------------------------------------------------------
    for (i in seq(0, n_total, by = chunk_size)) {
      nrows <- min(chunk_size, n_total - i)
      
      chunk <- fread(
        big_file,
        skip   = i + (i > 0),
        nrows  = nrows,
        header = (i == 0)
      )
      
      rows_so_far <- rows_so_far + nrow(chunk)
      cat(sprintf("Processed chunk %3d: %8d rows  |  total: %10d rows\n",
                  i / chunk_size + 1, nrow(chunk), rows_so_far))
      
      names(chunk) <- c("pat_id", "claimno", "rectype", "proc_cde", "ndc", "dayssup", "quan", "srv_unit", "from_dt", "to_dt", "diagprc_ind",
                        "diag1", "diag2", "diag3", "diag4", "diag5", "diag6", "diag7", "diag8", "diag9", "diag10", "diag11", "diag12", "bill_id",
                        "prscbr_id", "month_id")
       
      chunk <- select(chunk, c("pat_id", "from_dt", "to_dt"))
      
      # keep only IDs of interest
      chunk  <- id_tbl[chunk]          # fast keyed join
      
      # convert to IDate once
      chunk[, from_dt := as.IDate(from_dt)]
      chunk[, to_dt   := as.IDate(to_dt)]
      
      # summarise this chunk
      chunk_ranges <- chunk[
        , .(min_from = min(from_dt, na.rm = TRUE),
            max_to   = max(to_dt  , na.rm = TRUE)),
        by = pat_id
      ]
      
      # merge into master accumulator
      ranges <- merge(
        ranges, chunk_ranges, by = "pat_id", all = TRUE,
        suffixes = c("_old", "_new")
      )[
        , .(
            min_from = fifelse(is.na(min_from_old), min_from_new,
                               pmin(min_from_old, min_from_new, na.rm = TRUE)),
            max_to   = fifelse(is.na(max_to_old)  , max_to_new,
                               pmax(max_to_old  , max_to_new  , na.rm = TRUE))
          ),
        by = pat_id
      ]
      
      rm(chunk, chunk_ranges); gc()
    }

    saveRDS(ranges, "patient_enrollment_days.rds")
    ranges <- readRDS("patient_enrollment_days.rds")
    # ------------------------------------------------------------------
    # 3.  final enrolment span (days) ----------------------------------
    # ------------------------------------------------------------------
    ranges[, enrollment_days := as.integer(max_to - min_from) + 1L]

    # ranges now holds: pat_id | min_from | max_to | enrollment_days
    head(ranges)

## 6. Create dataset for virtual twin modeling analysis

    episode_model_sdoh <- fread("../Processed_data/Modeling/episode_model_df_v2.csv")

    # --- Create episode_model33 ---
    episode_model33 <- episode_model_sdoh %>%
      mutate(dayssup=episode.duration) %>%
      mutate(
        m_health = as.integer(
          depression == 1 | anxiety == 1 | ptsd == 1 | bipolar == 1 | schizo == 1
        )
      ) %>%
      mutate(age_group1 = case_when(
        age >=18 & age <= 24 ~ "18-24",
        age >=25 & age <= 34 ~ "25-34",
        age >=35 & age <= 44 ~ "35-44",
        age >=45 & age <= 54 ~ "45-54",
        age >=55 & age <= 64 ~ "55-64",
        age >=65 & age <= 85 ~ "65-85",
        TRUE ~ NA
      )) %>%
      mutate(age_binary= ifelse(age>=18 & age < 35, "18-34",
                             ifelse(age >=35 & age <=85, "35-85", NA))) %>%
      select(pat_id,episode.start,
        sex, pat_region, age_group, age_group1, age_binary, age, pay_type, dayssup,
        alcohol, nodrug, schizo, bipolar, anxiety, ptsd, depression,
        outpatient, psychiatric, mat, telehealth, induction, bupre_tx,
        discontinued, SVI_3digit_class,SVI_3digit_Rescale, providers_by_3ZIP_prop, group_MHAndSU, MHAndSU_3ZIP_count_prop, group_BP, 
        pdc_30, pdc_90, m_health
      )

    saveRDS(episode_model33, "../Processed_data/Modeling/episode_ML_v2.rds")

**episode\_ML\_v2.rds is the analytical dataset for virtual twin
analysis **

## 7. Create time to event outcomes for Cox model

    episode_demo_duration <- episode_model %>%
      mutate(
        time = episode.duration,
        status = ifelse(episode.duration < 180, 1, 0)
      )

    ### save 
    saveRDS(episode_demo_duration, "episode_demo_duration.rds")

**NOTE - The episode\_demo\_duration data is used in the Cox PH
analysis, and saved on the server**
